{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lGCokrsP45Z6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from mordred import Calculator, descriptors\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import dump, load\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Target:\n",
    "    \n",
    "    # path: the path to ligands and decoys .ism files\n",
    "    def __init__ (self, path):\n",
    "        self.path=path\n",
    "        \n",
    "    calc = Calculator(descriptors, ignore_3D=True)\n",
    "    \n",
    "    def ligand_batch_size (self):\n",
    "        with open (f'{self.path}actives_final.ism', 'r') as f :\n",
    "            return len(f.readlines ())\n",
    "    \n",
    "    def actives (self) :\n",
    "        with open (f'{self.path}actives_final.ism', 'r') as f :\n",
    "            actives = list(map(lambda x : x.split (' ')[0], f.readlines ()))\n",
    "        active_mols = list(map(Chem.MolFromSmiles,actives))\n",
    "        active_df = self.calc.pandas(active_mols, display=False)\n",
    "        active_df['Active']=1\n",
    "        print (f\"Actives done\")\n",
    "        return active_df\n",
    "    \n",
    "    # Decoys dataframe is constructed with size of three-time as size of actives\n",
    "    # to avoid imbalancity\n",
    "    \n",
    "    def decoys (self) :\n",
    "        with open (f'{self.path}decoys_final.ism', 'r') as f :\n",
    "            decoys = list(map(lambda x : x.split (' ')[0], f.readlines ()))\n",
    "        rand = randint(0,len(decoys)//2)\n",
    "        decoys_mols = list(map(Chem.MolFromSmiles,decoys[rand:rand+(self.ligand_batch_size()*3)]))\n",
    "        decoys_df = self.calc.pandas(decoys_mols)\n",
    "        decoys_df['Active']=0\n",
    "        print (f\"Decoys done\")\n",
    "        return decoys_df\n",
    "    \n",
    "    def all_mols (self):\n",
    "        df=pd.concat([self.actives(),self.decoys()], axis=0)\n",
    "        df.to_csv(f\"{self.path.split('/')[-2]}.csv\", index=False)\n",
    "        print(f\"{self.path.split('/')[-1]} Done!\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, name, path=os.getcwd()):\n",
    "        self.name=name\n",
    "        self.df=pd.read_csv(f\"{path}/{name}.csv\", low_memory=False).select_dtypes(np.number)\n",
    "        self.current_df=0\n",
    "        self.clf=0\n",
    "        self.results=0\n",
    "    \n",
    "    # Feature Selection based on Corelation and Variance\n",
    "    # correlation_threshold : int\n",
    "    # variance_threshold : float\n",
    "    \n",
    "    def feature_selection(self,correlation_threshold=150, variance_threshold=0.005):\n",
    "        sel = VarianceThreshold(0.2)\n",
    "        final_selected = pd.concat([self.df.iloc[:,:-1].loc[:, sel.fit(self.df.iloc[:,:-1]).get_support()],self.df.iloc[:,-1:]], axis=1)\n",
    "        print (\"variance-based selection done!\")\n",
    "        corrmat = final_selected.corr().abs().unstack()\n",
    "        print (\"matrix of correlations constructed!\")\n",
    "        corrmat = corrmat[corrmat >= 0.8]\n",
    "        corrmat = corrmat[corrmat < 1]\n",
    "        corrmat = pd.DataFrame(corrmat).reset_index()\n",
    "        corrmat.columns = ['feature1', 'feature2', 'corr']\n",
    "        corellated_features=corrmat[\"feature1\"].tolist()\n",
    "        frq={}\n",
    "        for i in range (len(corellated_features)):\n",
    "            if corellated_features[i] not in frq:\n",
    "                frq[corellated_features[i]]=1\n",
    "            else:\n",
    "                frq[corellated_features[i]]+=1\n",
    "        highly_correlated=[k for k in sorted(frq, key=frq.get, reverse=True) if frq[k]>correlation_threshold]\n",
    "        final_selected.drop(columns=highly_correlated)\n",
    "        self.current_df = final_selected\n",
    "        print ('features selected!')\n",
    "        return final_selected\n",
    "    \n",
    "    # Scaling preprocess.\n",
    "    # using StandardScaler\n",
    "    \n",
    "    def scale (self):\n",
    "        scaling_df = self.feature_selection()\n",
    "        scaler = StandardScaler()\n",
    "        scaling_df.iloc[:,1:-1] = pd.DataFrame(scaler.fit_transform(scaling_df.iloc[:,1:-1].values),\n",
    "                                              columns=scaling_df.iloc[:,1:-1].columns,\n",
    "                                              index=scaling_df.iloc[:,1:-1].index)\n",
    "        self.current_df = scaling_df\n",
    "        print (\"scaled!\")\n",
    "        return scaling_df\n",
    "    \n",
    "    # Building the model\n",
    "    \n",
    "    def modeler(self, save_path=os.getcwd()):\n",
    "        df = self.scale()\n",
    "        X = df.iloc[:,:-1]\n",
    "        y = df.iloc[:,-1]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "        clf = LogisticRegressionCV(cv=5, Cs=[0.5, 1, 5, 10], random_state=0,\n",
    "                                   penalty = 'elasticnet', solver='saga', max_iter=5000,\n",
    "                                   l1_ratios=[0.25,0.5,0.75], n_jobs=-1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        self.clf=clf\n",
    "        print (\"model trained!\")\n",
    "        y_pred = clf.predict (X_test)\n",
    "        y_true = y_test\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        fb = fbeta_score(y_true, y_pred, beta = 0.5)\n",
    "        balanced_accuracy = balanced_accuracy_score(y_true, y_pred)\n",
    "        filename = f\"{save_path}/{self.name}.sav\"\n",
    "        dump(clf, filename)\n",
    "        test_results=list(zip(df.columns,clf.coef_[0])) + [(\"F1 score\",f1) + (\"F-Beta score\", fb) +\n",
    "                                                     (\"Balanced Accuracy score\", balanced_accuracy)]\n",
    "        self.results=test_results\n",
    "        return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating ratio of highly correlated features for each target\n",
    "def corr_mapper (x):\n",
    "    a=0\n",
    "    if x>=0.5 and x!=1:\n",
    "        a=1\n",
    "    elif x==1:\n",
    "        a=0\n",
    "    return a\n",
    "corr_matrix = [pd.read_csv(f\"dfs/{tar}\",low_memory=False).select_dtypes(np.number).corr() for tar in dfs]\n",
    "corr_mapped=[np.vectorize(corr_mapper)(corr_matrix_tar[:]) for corr_matrix_tar in corr_matrix]\n",
    "high_corrs=[np.sum(corr_mapped_tar)/corr_mapped_tar.size for corr_mapped_tar in corr_mapped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = os.listdir(\"dfs\")\n",
    "names = [tar.split(\".\")[0] for tar in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('F1 score', 0.9868421052631579, 'F-Beta score', 0.9907529722589169, 'Balanced Accuracy score', 0.9890027610089381)\n"
     ]
    }
   ],
   "source": [
    "print (f\"{names[0]}\")\n",
    "mmp13 = Model(f\"{names[0]}\",\"dfs\")\n",
    "mmp13_scores = mmp13.modeler(\"dfs\")\n",
    "print (mmp13_scores[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fa10\n",
      "variance-based selection done!\n",
      "matrix of correlations constructed!\n",
      "features selected!\n",
      "scaled!\n",
      "model trained!\n",
      "('F1 score', 0.993006993006993, 'F-Beta score', 0.9930069930069931, 'Balanced Accuracy score', 0.9952344609705016)\n"
     ]
    }
   ],
   "source": [
    "print (f\"{names[1]}\")\n",
    "fa10 = Model(f\"{names[1]}\",\"dfs\")\n",
    "fa10_scores = fa10.modeler(\"dfs\")\n",
    "print (fa10_scores[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpp4\n",
      "variance-based selection done!\n",
      "matrix of correlations constructed!\n",
      "features selected!\n",
      "scaled!\n",
      "model trained!\n",
      "('F1 score', 0.9964412811387899, 'F-Beta score', 0.9943181818181818, 'Balanced Accuracy score', 0.9987277353689568)\n"
     ]
    }
   ],
   "source": [
    "print (f\"{names[2]}\")\n",
    "dpp4 = Model(f\"{names[2]}\",\"dfs\")\n",
    "dpp4_scores = dpp4.modeler(\"dfs\")\n",
    "print (dpp4_scores[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mk14\n",
      "variance-based selection done!\n",
      "matrix of correlations constructed!\n",
      "features selected!\n",
      "scaled!\n",
      "model trained!\n",
      "('F1 score', 0.9770491803278689, 'F-Beta score', 0.9675324675324676, 'Balanced Accuracy score', 0.9896573208722741)\n"
     ]
    }
   ],
   "source": [
    "print (f\"{names[3]}\")\n",
    "mk14 = Model(f\"{names[3]}\",\"dfs\")\n",
    "mk14_scores = mk14.modeler(\"dfs\")\n",
    "print (mk14_scores[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled11.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
